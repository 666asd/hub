# Default values for bd.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

nameOverride: ""
fullnameOverride: ""

isKubernetes: true

imageTag: 2020.2.0

# Docker registry to pull Black Duck images
registry: docker.io/blackducksoftware

# image pull secret to download the Black Duck images (mostly applicable for air gapped customers)
imagePullSecrets: [] # array of strings delimited by comma

sealKey: abcdefghijklmnopqrstuvwxyz123456 # length of 32 characters - to be used to encrypt the master key for source code upload

# enable Persistent Storage for containers
enablePersistentStorage: true
storageClass: # it will apply to all PVC's storage class but it can be override at container level

# enable Liveness probe
enableLivenessProbe: true

# Source code upload
enableSourceCodeUpload: false
dataRetentionInDays: 180 # days to retain the data
maxTotalSourceSizeinMB: 4000 # maximum size of total source file size in MB

# enable binary scanner
enableBinaryScanner: false

# configure Black Duck to use an Alert instance
enableAlert: false

# enable IPV6
enableIPV6: false

# TLS certificate for Black Duck
# create a generic secret using the following command
# kubectl create secret generic -n <namespace> <name>-blackduck-webserver-certificate --from-file=WEBSERVER_CUSTOM_CERT_FILE=tls.crt --from-file=WEBSERVER_CUSTOM_KEY_FILE=tls.key
# tlsCertSecretName: blackduck-webserver-certificate

# Certificate Authentication Custom CA certificate for Black Duck (Not Mandatory)
# create a generic secret using the following command
# kubectl create secret generic -n <namespace> <name>-blackduck-auth-custom-ca --from-file=AUTH_CUSTOM_CA=ca.crt
certAuthCACertSecretName:

# Proxy certificate for Black Duck (Not Mandatory)
# create a generic secret using the following command
# kubectl create secret generic -n <namespace> <name>-blackduck-proxy-certificate --from-file=HUB_PROXY_CERT_FILE=proxy.crt
proxyCertSecretName:

# This is used to start or stop the hub. Set to Running to start the hub, or Stopped to stop the hub.
status: Running

# additional environ values that need to be added into Black Duck configuration
# go to templates/configmap.yaml to configure existing environs
# if you are setting the value using set flag in helm command, do --set environs.* = ""; i.e.: --set environs.HUB_POSTGRES_CONNECTION_ADMIN="blackduck@pg-server-name"
environs:
  BLACKDUCK_CFSSL_PORT: "8888"
  BROKER_USE_SSL: "yes"
  HTTPS_VERIFY_CERTS: "yes"
  RABBIT_MQ_PORT: "5671"
  RABBITMQ_DEFAULT_VHOST: "protecodesc"
  RABBITMQ_SSL_FAIL_IF_NO_PEER_CERT: "false"
  RUN_SECRETS_DIR: "/tmp/secrets"
  SCANNER_CONCURRENCY: "1"

postgres:
  registry: registry.access.redhat.com/rhscl # override the docker registry at container level
  isExternal: true # false for running Postgres as a container and true for using External Postgres database (Initialization need to handled by customer)
  host: # required only for external postgres, for postgres as a container, it will point to <name>-blackduck-postgres
  port: 5432
  adminUserName: blackduck
  adminPassword: testPassword
  userUserName: blackduck_user
  userPassword: testPassword
  ssl: true # If true, Black Duck uses SSL for external Postgres connection
  postgresPassword: testPassword # required only in case of Postgres as a container
  persistentVolumeClaimName: {}
  claimSize: 150Gi # PVC claim size
  storageClass: # PVC storage class name
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  resources: {}

init:
  registry: # override the docker registry at container level
  imageTag: 1.0.0
  securityContext: {}

authentication:
  registry: # override the docker registry at container level
  imageTag: 2020.2.0
  persistentVolumeClaimName: {}
  claimSize: 2Gi # PVC claim size
  storageClass: # PVC storage class name
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  hubMaxMemory: "512m"  # jvm max heap memory -Xmx [NOTE: THIS SHOULD BE SET RELATIVELY TO resources.limits.memory (specifically less than resources.limits.memory)]
  resources:
    limits:
      memory: "1024Mi"

binaryscanner:
  registry: docker.io/sigsynopsys # override the docker registry at container level
  imageTag: 2019.12
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  resources:
    limits:
      cpu: "1000m"
      memory: "2048Mi"

cfssl:
  registry: # override the docker registry at container level
  imageTag: 1.0.1
  persistentVolumeClaimName: {}
  claimSize: 2Gi # PVC claim size
  storageClass: # PVC storage class name
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  resources:
    limits:
      memory: "640Mi"

documentation:
  registry: # override the docker registry at container level
  imageTag: 2020.2.0
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  resources:
    limits:
      memory: "512Mi"

jobrunner:
  registry: # override the docker registry at container level
  imageTag: 2020.2.0
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  replicas: 1
  hubMaxMemory: "4096m" # jvm max heap memory -Xmx [NOTE: THIS SHOULD BE SET RELATIVELY TO resources.limits.memory (specifically less than resources.limits.memory)]
  resources: {}

rabbitmq:
  registry: # override the docker registry at container level
  imageTag: 1.0.3
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  resources:
    limits:
      memory: "1024Mi"

registration:
  registry: # override the docker registry at container level
  imageTag: 2020.2.0
  persistentVolumeClaimName: {}
  claimSize: 2Gi # PVC claim size
  storageClass: # PVC storage class name
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  resources:
    requests:
      cpu: "1000m"
    limits:
      memory: "1024Mi"

scan:
  registry: # override the docker registry at container level
  imageTag: 2020.2.0
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  replicas: 1
  hubMaxMemory: "2048m" # jvm max heap memory -Xmx [NOTE: THIS SHOULD BE SET RELATIVELY TO resources.limits.memory (specifically less than resources.limits.memory)]
  resources: {}

uploadcache:
  registry: # override the docker registry at container level
  imageTag: 1.0.13
  persistentVolumeClaimName: {}
  claimSize: 100Gi # PVC claim size
  storageClass: # PVC storage class name
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  resources:
    limits:
      memory: "512Mi"

webapp:
  registry: # override the docker registry at container level
  imageTag: 2020.2.0
  persistentVolumeClaimName: {}
  claimSize: 2Gi # PVC claim size
  storageClass: # PVC storage class name
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  hubMaxMemory: "2048m" # jvm max heap memory -Xmx [NOTE: THIS SHOULD BE SET RELATIVELY TO resources.limits.memory (specifically less than resources.limits.memory)]
  resources: {}

logstash:
  registry: # override the docker registry at container level
  imageTag: 1.0.5
  persistentVolumeClaimName: {}
  claimSize: 20Gi # PVC claim size
  storageClass: # PVC storage class name
  nodeSelector: {}
  tolerations: []
  affinity: {}
  securityContext: {} #podSecurityContext is set in webapp above
  resources:
    limits:
      memory: "1024Mi"

webserver:
  registry: # override the docker registry at container level
  imageTag: 1.0.18
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  resources: {}

zookeeper:
  registry: # override the docker registry at container level
  imageTag: 1.0.3
  persistentVolumeClaimName: {}
  claimSize: 4Gi # PVC claim size
  storageClass: # PVC storage class name
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  securityContext: {}
  resources:
    requests:
      cpu: "1000m"
    limits:
      memory: "640Mi"

